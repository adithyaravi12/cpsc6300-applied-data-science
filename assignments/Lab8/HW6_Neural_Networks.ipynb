{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-zY93Wz26cV"
   },
   "source": [
    "<div class='heading'>\n",
    "    <div style='float:left;'><h1>CPSC 4300/6300: Applied Data Science</h1></div>\n",
    "    <img style=\"float: right; padding-right: 10px; width: 65px\" src=\"https://raw.githubusercontent.com/bsethwalker/clemson-cs4300/main/images/clemson_paw.png\"> </div>\n",
    "\n",
    "\n",
    "## Homework 7: Neural Networks\n",
    "\n",
    "**Clemson University**<br>\n",
    "**Spring 2023**<br>\n",
    "**Instructor(s):** Carlos Toxtli & Nina Hubig <br>\n",
    "**Author(s):** Brandon Walker\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "JEFuaZhz26cX",
    "outputId": "55dae801-9819-45e0-9ba1-bfcb089b007a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "\n",
       "div.heading {\n",
       "margin-bottom: 25px;\n",
       "height: 75px;\n",
       "}\n",
       "\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "    \n",
       "    background: rgba(245, 102, 0, .75);\n",
       "    border-color: #E9967A;\n",
       "    border-left: 5px solid #522D80; \n",
       "    padding: 0.5em;\n",
       "}\n",
       "\n",
       "div.exercise-r {\n",
       "    background-color: #fce8e8;\n",
       "    border-color: #E9967A; \t\n",
       "    border-left: 5px solid #800080; \n",
       "    padding: 0.5em;\n",
       "}\n",
       "\n",
       "span.sub-q {\n",
       "    font-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "    background-color: #DDDDDD;\n",
       "    border-color: #E9967A; \t\n",
       "    border-left: 5px solid #800080; \n",
       "    padding: 0.5em;\n",
       "    font-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "    background-color: #AEDE94;\n",
       "    border-color: #E9967A; \t \n",
       "    border-left: 5px solid #800080; \n",
       "    padding: 0.5em;\n",
       "    font-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" RUN THIS CELL TO GET THE RIGHT FORMATTING \"\"\"\n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "css_file = 'https://raw.githubusercontent.com/bsethwalker/clemson-cs4300/main/css/cpsc6300.css'\n",
    "styles = requests.get(css_file).text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPbY6Xxp26cY"
   },
   "source": [
    "### INSTRUCTIONS\n",
    "\n",
    "- To submit your assignment, follow the instructions given in Canvas.\n",
    "- Restart the kernel and run the whole notebook again before you submit. \n",
    "- As much as possible, try and stick to the hints and functions we import at the top of the homework, as those are the ideas and tools the class supports and are aiming to teach. And, if a problem specifies a particular library, you're required to use that library, and possibly others from the import list.\n",
    "- Please use .head() when viewing data. Do not submit a notebook that is excessively long because output was not suppressed or otherwise limited. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vwdv08BaIve6"
   },
   "source": [
    "Instructions for installing Tensorflow using pip https://www.tensorflow.org/install/pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVXsNshv26cY"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(112358)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "# from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5aLFu1oo26cY",
    "outputId": "018eccda-28a2-4692-90f4-d4701fe16177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCJGoktq26cZ"
   },
   "source": [
    "<div class='theme'> Neural Networks</div> \n",
    "\n",
    "Neural networks are, of course, a large and complex topic that cannot be covered in a single homework. Here, we'll focus on the key idea of ANNs: they are able to learn a mapping from example input data $X$ (of fixed size) to example output data $Y$ (of fixed size). This is the same concept as every other classification and regression task we've learned so far in the semester. We'll also partially explore what patterns the neural network learns and how well neural networks generalize.\n",
    "\n",
    "In this question, we'll see if neural networks can learn a limited version of the [Fourier Transform.](https://en.wikipedia.org/wiki/Fourier_transform) (The Fourier Transform takes in values from some function and returns a set of sine and cosine functions which, when added together, approximate the original function.)\n",
    "\n",
    "In symbols: $ \\cal{F(s)} = \\int_{-\\infty}^\\infty f(x)e^{- i xs}dx$. In words, the value of the transformed function at some point, $s$, is the value of an integral which measures, in some sense, how much the original $f(x)$ looks like a wave with a period of $s$. As an example, with $f(x) = 4cos(x) + sin(2x)$,  $\\cal{F}(s)$ is 0 everywhere except at -2, -1, 1, and 2, mapping to the waves of period 1 and 1/2. The values at these points are linked to the magnitude of the waves, and their phases (roughly: sin waves versus cosine waves).\n",
    "\n",
    "The only thing about the Fourier transform that matters for this p-set is this: a function goes in, and a re-written form in terms of sine and cosine comes out.\n",
    "\n",
    "In our specific problem, we'll train a network to map from 1000 sample values from a function (equally spaced along 0 to 10$\\pi$) to the four features of the sine and cosine waves that make up that function. Thus, the network is attempting to learn a mapping from a 1000-entry vector down to a 4-entry vector. Our `X_train` dataset's shape is $N x 1000$ and our `y_train` is $N x 4.$\n",
    "\n",
    "Questions 1.1 and 1.2 will get you used to the format of the data. \n",
    "\n",
    "We'll use 6 data files in this question:\n",
    "- `sinewaves_X_train.npy` and `sinewaves_y_train.npy`: a (10,000 x 1,000) and (10,000 x 4) training dataset. Examples were generated by randomly selecting a,b,c,d in the interval [0,1] and building the curve $a\\sin(b\\,x) + c\\cos(d\\,x)$\n",
    "- `sinewaves_X_test.npy` and `sinewaves_y_test.npy`: a (2,000 x 1,000) and (2,000 x 4) test dataset, generated in the same way as the training data\n",
    "- `sinewaves_X_extended_test` and `sinewaves_y_extended_test`: a (9 x 1,000) and (9 x 4) test dataset, testing whether the network can generalize beyond the training data (e.g. to negative values of $a$)\n",
    "\n",
    "**These datasets are read in to their respective variables for you.**\n",
    "\n",
    "**Hint**:\n",
    "- The Tensorflow [`tf.keras` (here)](https://www.tensorflow.org/guide/keras) documentation and examples of a Sequential model are a good place to start.\n",
    "- A strong model can achieve validation error of around 0.03 on this data and 0.02 is very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ux9ZWVUB26cZ"
   },
   "outputs": [],
   "source": [
    "def plot_predictions(model, test_x, test_y, count=None):\n",
    "    # Model - a tf.keras model that takes in (n,1000) training data and predicts (n,4) output data\n",
    "    # test_x - a (n,1000) input dataset\n",
    "    # test_y - a (n,4) output dataset\n",
    "    # This function will plot the sine curves in the training data and those implied by the model's predictions.\n",
    "    # It will also print the predicted and actual output values.\n",
    "    \n",
    "    #helper function that takes the n by 4 output and reverse-engineers \n",
    "    #the sine curves that output would create\n",
    "    def y2x(y_data):\n",
    "        #extract parameters\n",
    "        a=y_data[:,0].reshape(-1,1)\n",
    "        b=y_data[:,1].reshape(-1,1)\n",
    "        c=y_data[:,2].reshape(-1,1)\n",
    "        d=y_data[:,3].reshape(-1,1)\n",
    "\n",
    "        #build the matching training data\n",
    "        x_points = np.linspace(0,10*np.pi,1000)\n",
    "        x_data = a*np.sin(np.outer(b,x_points)) + c*np.cos(np.outer(d,x_points))\n",
    "        return x_data\n",
    "    \n",
    "    #if <20 examples, plot all. If more, just plot 5\n",
    "    if count==None:\n",
    "        if test_x.shape[0]>20:\n",
    "            count=5\n",
    "        else:\n",
    "            count=test_x.shape[0]\n",
    "    \n",
    "    #build predictions\n",
    "    predicted = model.predict(test_x)\n",
    "    implied_x = y2x(predicted)\n",
    "    for i in range(count):\n",
    "        plt.plot(test_x[i,:],label='true')\n",
    "        plt.plot(implied_x[i,:],label='predicted')\n",
    "        plt.legend()\n",
    "        plt.ylim(-2.1,2.1)\n",
    "        plt.xlabel(\"x value\")\n",
    "        plt.xlabel(\"y value\")\n",
    "        plt.title(\"Curves using the Neural Network's Approximate Fourier Transform\")\n",
    "        plt.show()\n",
    "        print(\"true:\", test_y[i,:])\n",
    "        print(\"predicted:\", predicted[i,:])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AL1JcO4926cZ"
   },
   "outputs": [],
   "source": [
    "X_train = np.load('sinewaves_X_train.npy')\n",
    "y_train = np.load('sinewaves_y_train.npy')\n",
    "\n",
    "X_test = np.load('sinewaves_X_test.npy')\n",
    "y_test = np.load('sinewaves_y_test.npy')\n",
    "\n",
    "X_extended_test = np.load('sinewaves_X_extended_test.npy')\n",
    "y_extended_test = np.load('sinewaves_y_extended_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yh0TeVx126cZ"
   },
   "source": [
    "<hr style='height:2pt'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlTjKXLW26ca"
   },
   "source": [
    "<div class='exercise'> <b> Question 1 </b> </div>\n",
    "Plot the first row of the `X_train` training data and visually verify that it is a sinusoidal curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uOHDq2tk26ca"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmXv7eif26ca"
   },
   "source": [
    "<div class='exercise'> <b> Question 2 </b> </div>\n",
    "\n",
    "The first row of the `y_train` data is $[0.024, 0.533, 0.018, 0.558]$. Visually verify that the first row of X_train is 1000 equally-spaced points in $[0,10\\pi]$ from the function $f(x) = 0.024\\sin(0.533\\,x) + 0.018\\cos(0.558\\,x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SN-KoSQV26ca",
    "outputId": "b79c47a1-08e2-425a-d8d7-8ac472017dd6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.024, 0.533, 0.018, 0.558])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vj3g9AZ026ca"
   },
   "outputs": [],
   "source": [
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--BwpyJr26ca"
   },
   "source": [
    "<div class='exercise'> <b> Question 3 </b> </div>\n",
    "Use `tf.keras` to build a fully-connected neural network:\n",
    "\n",
    "**a:** Use `tf.keras.models.Sequential` and `tf.keras.layers.Dense` to build the fully-connected neural network. You can choose any number of layers and any number of nodes in each layer. Remember that as a regression problem, the last layer activation should be `linear`.\n",
    "\n",
    "**b:** Compile your model via the line `model.compile(loss='mean_absolute_error', optimizer='adam')` and display the `.summary()`. Explain why the first layer in your network has the indicated number of parameters.\n",
    "\n",
    "**c:** Fit your model to the data for $50$ epochs using a batch size of $32$ and a validation split of $0.2$. You can train for longer if you wish -- the fit tends to improve over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bl5ToOiE26ca"
   },
   "outputs": [],
   "source": [
    "# build the fully-connected neural network\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oTI-thV526ca"
   },
   "outputs": [],
   "source": [
    "# Compile your model \n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sU3etmU26ca"
   },
   "source": [
    "*your answer here*\n",
    "There are 25025 params in the first layer. This is due to we have around 10000 values as input.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pLqW6lNW26ca"
   },
   "outputs": [],
   "source": [
    "# Fit your model \n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bS4gNCWy26cb"
   },
   "source": [
    "<div class='exercise'> <b> Question 4 </b> </div>\n",
    "\n",
    "Use the `plot_predictions` function to plot the model's predictions on `X_test` to the true values in `y_test` (by default, it will only plot the first few rows). Report the model's overall loss on the test set. Comment on how well the model performs on this unseen data. Do you think it has accurately learned how to map from sample data to the coefecients that generated the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "krDIQLIJ26cb"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQ7X9r3K26cb"
   },
   "outputs": [],
   "source": [
    "# model's overall loss\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OM3ALcUH26cb"
   },
   "source": [
    "*your answer here*\n",
    "...\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q88-ff3S26cb"
   },
   "source": [
    "<div class='exercise'> <b> Question 5 </b> </div>\n",
    "Examine the model's performance on the 9 train/test pairs in the `extended_test` variables. Which examples does the model do well on, and which examples does it struggle with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlXbU6eC26cb"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLerfvd926cb"
   },
   "source": [
    "*Your answer here*\n",
    "After evaluating the model performance on 9 pairs, model two worked well and model 4 has struggled.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6z7_RgUa26cb"
   },
   "source": [
    "<div class='exercise'> <b> Question 6 </b> </div>\n",
    "Is there something that stands out about the difficult observations, especially with respect to the data the model was trained on? Did the model learn the mapping we had in mind? Would you say the model is overfit, underfit, or neither?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7yTVRrQ26cb"
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yo1IZ6N26cb"
   },
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
